{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to convert to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return value  # If conversion fails, return the original value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Node class\n",
    "This class defines a single node. It can be root node, leaf etc depends on the position in the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_name=None, threshold=None, left_tree=None, right_tree=None, information_gain=None, leaf_value=None):\n",
    "        \n",
    "        self.feature_name = feature_name\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.left = left_tree       # Node\n",
    "        self.right = right_tree     # Node\n",
    "        \n",
    "        self.information_gain = information_gain\n",
    "        \n",
    "        #If the node is a leaf node this value will be set\n",
    "        self.leaf_value = leaf_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Enum SplitCriterion\n",
    " Enum is used to define the split criterion ie. gini or entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class SplitCriterion(Enum):\n",
    "    GINI = \"gini\"\n",
    "    ENTROPY = \"entropy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DecisionTreeData class\n",
    "This class holds all the data for a execution\n",
    "All the configurations or modification of the data for the classifier is in this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeData:\n",
    "    def __init__(self, source_data_frame,criterion:SplitCriterion,is_auto_column_type = False,remove_nulls = False) -> None:\n",
    "        \n",
    "        if(remove_nulls == True):\n",
    "            source_data_frame.replace('?', pd.NA, inplace=True)\n",
    "            source_data_frame.dropna(inplace=True)\n",
    "            source_data_frame.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        self.source_data_frame = source_data_frame\n",
    "        self.features_columns_names = []\n",
    "        self.class_column_name = ''\n",
    "        self.real_columns_names = []\n",
    "        self.nominal_column_names = []\n",
    "        self.tree = Node()\n",
    "        self.class_values = []\n",
    "        self.feature_column_values = []\n",
    "        self.criterion = criterion\n",
    "        self.training_data = []\n",
    "        self.test_data = []\n",
    "        self.is_auto_column_type = is_auto_column_type\n",
    "        self.folds = {}\n",
    "\n",
    "    def set_column_type(self,real_columns_names,nominal_column_names):\n",
    "            self.real_columns_names = real_columns_names\n",
    "            self.nominal_column_names = nominal_column_names\n",
    "            \n",
    "            #Apply the column data type to the data\n",
    "            self.source_data_frame[real_columns_names] = self.source_data_frame[real_columns_names].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "    def process(self):\n",
    "        self.feature_column_values = self.source_data_frame.iloc[:, :-1]\n",
    "        self.class_values = self.source_data_frame.iloc[:, -1]\n",
    "\n",
    "        self.class_column_name = self.source_data_frame.columns[-1]\n",
    "\n",
    "        self.features_columns_names = self.feature_column_values.columns\n",
    "        \n",
    "        # If is_auto_column_type is true then system will calculate the column data type\n",
    "        # Otherwise we need to specify the colum data type\n",
    "        if(self.is_auto_column_type == True):\n",
    "            self.identify_colum_types()\n",
    "            \n",
    "    def convert_nominal_values_to_real(self):\n",
    "        self.source_data_frame = pd.get_dummies(self.source_data_frame, columns=self.nominal_column_names)\n",
    "        \n",
    "    def identify_colum_types(self):\n",
    "        column_types = self.feature_column_values.dtypes\n",
    "\n",
    "        self.real_columns_names = [col for col, dtype in column_types.items() if dtype in ['int64', 'float64']]\n",
    "        self.nominal_column_names = [col for col, dtype in column_types.items() if dtype == 'object']\n",
    "        \n",
    "    def train_test_split(self):\n",
    "        shuffled_data = self.source_data_frame.sample(frac=1)\n",
    "        split_point = int(0.8 * len(self.source_data_frame))\n",
    "\n",
    "        self.training_data = shuffled_data.iloc[:split_point]\n",
    "        self.test_data = shuffled_data.iloc[split_point:]\n",
    "        \n",
    "    def generate_folds(self,fold_count):\n",
    "        rows_per_fold = len(self.source_data_frame)/fold_count\n",
    "        self.folds = {}\n",
    "        shuffled_data = self.source_data_frame.sample(frac=1)\n",
    "        \n",
    "        for i in range(fold_count):\n",
    "            start_index = int(i * rows_per_fold)\n",
    "            end_index = int((i + 1) * rows_per_fold)\n",
    "            subset = shuffled_data.iloc[start_index:end_index]\n",
    "            self.folds[i] = subset\n",
    "            \n",
    "    def reset_training_test_data(self,training_data,test_data):\n",
    "        self.training_data = training_data\n",
    "        self.test_data = test_data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DecisionTreeSplit\n",
    "This class is a model class for giving a format to the each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeSplit:\n",
    "    def __init__(self, feature_name = None,threshold = None,left_dataset = None,right_dataset = None,information_gain = -float(\"inf\")):\n",
    "        self.feature_name = feature_name\n",
    "        self.threshold = threshold\n",
    "        self.left_dataset = left_dataset\n",
    "        self.right_dataset = right_dataset\n",
    "        self.information_gain = information_gain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DecisionTreeClassifier Class\n",
    "This is the decision tree classifier class works with the data - DecisionTreeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self,decisionTreeData:DecisionTreeData,min_samples = 2,max_depth = 2) -> None:\n",
    "        self.decisionTreeData = decisionTreeData\n",
    "        self.min_samples = min_samples\n",
    "        self.max_depth =  max_depth\n",
    "        \n",
    "    def execute(self):\n",
    "        self.decisionTreeData.tree = self.build_tree(self.decisionTreeData.training_data,0)\n",
    "        \n",
    "    def calculate_entropy(self,labels):\n",
    "        _ , counts = np.unique(labels, return_counts=True)\n",
    "        probabilities = counts / len(labels)\n",
    "        entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "        return entropy\n",
    "    \n",
    "    def calculate_gini(self,labels):\n",
    "        _ , counts = np.unique(labels, return_counts=True)\n",
    "        probabilities = counts / len(labels)\n",
    "        gini_impurity = 1 - np.sum(probabilities**2)\n",
    "        return gini_impurity\n",
    "    \n",
    "    def split_real_valued_feature(self, dataset, feature_index):\n",
    "        mean_value = dataset[feature_index].mean()\n",
    "        dataset_left = dataset[dataset[feature_index] < mean_value]\n",
    "        dataset_right = dataset[dataset[feature_index] >= mean_value]\n",
    "        return dataset_left, dataset_right, mean_value\n",
    "\n",
    "    def split_nominal_valued_feature(self, dataset, feature_index, threshold):\n",
    "        dataset_left = dataset[dataset[feature_index] == threshold]\n",
    "        dataset_right = dataset[dataset[feature_index] != threshold]\n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    def get_majority_class(self, data):\n",
    "        return data[self.decisionTreeData.class_column_name].mode().iloc[0]\n",
    "    \n",
    "    def build_tree(self, data, depth=0):\n",
    "        decision_tree_split = self.find_best_split(data)\n",
    "\n",
    "        if depth >= self.max_depth or len(data) <= self.min_samples:\n",
    "            majority_class = self.get_majority_class(data)\n",
    "            return Node(leaf_value=majority_class)\n",
    "\n",
    "        if(decision_tree_split.information_gain > 0):\n",
    "            left_tree = self.build_tree(decision_tree_split.left_dataset, depth + 1)\n",
    "            right_tree = self.build_tree(decision_tree_split.right_dataset, depth + 1)\n",
    "\n",
    "            return Node(decision_tree_split.feature_name,\n",
    "                        decision_tree_split.threshold,\n",
    "                        left_tree,\n",
    "                        right_tree,\n",
    "                        decision_tree_split.information_gain)\n",
    "        \n",
    "        return Node(leaf_value=self.get_majority_class(data))\n",
    "        \n",
    "    def information_gain(self, parent, left_child, right_child):        \n",
    "        weight_l = len(left_child) / len(parent)\n",
    "        weight_r = len(right_child) / len(parent)\n",
    "        if self.decisionTreeData.criterion == SplitCriterion.GINI:\n",
    "            gain = self.calculate_gini(parent) - (weight_l*self.calculate_gini(left_child) + weight_r*self.calculate_gini(right_child))\n",
    "            \n",
    "        else:\n",
    "            gain = self.calculate_entropy(parent) - (weight_l*self.calculate_entropy(left_child) + weight_r*self.calculate_entropy(right_child))\n",
    "            \n",
    "        return gain\n",
    "\n",
    "    def find_best_split(self,dataset):\n",
    "        best_feature_split = DecisionTreeSplit()\n",
    "        \n",
    "        for feature_name in self.decisionTreeData.features_columns_names:\n",
    "            feature_values = dataset[feature_name]\n",
    "            \n",
    "            if(self.decisionTreeData.real_columns_names.__contains__(feature_name)):\n",
    "                left_dataset,right_dataset,threshold =  self.split_real_valued_feature(dataset,feature_name)\n",
    "                self.calculate_best_feature(dataset, best_feature_split, feature_name, left_dataset, right_dataset, threshold)\n",
    "               \n",
    "            else:\n",
    "                for threshold in np.unique(feature_values):\n",
    "                    left_dataset, right_dataset = self.split_nominal_valued_feature(dataset, feature_name, threshold)\n",
    "                    self.calculate_best_feature(dataset, best_feature_split, feature_name, left_dataset, right_dataset, threshold)\n",
    "                        \n",
    "        return best_feature_split\n",
    "\n",
    "    def calculate_best_feature(self, dataset, best_split, feature_name, left_dataset, right_dataset, threshold):\n",
    "        parent_data_class_values= dataset[self.decisionTreeData.class_column_name]\n",
    "        left_class_values  = left_dataset[self.decisionTreeData.class_column_name]\n",
    "        right_class_values = right_dataset[self.decisionTreeData.class_column_name]\n",
    "        \n",
    "        current_info_gain = self.information_gain(parent_data_class_values, left_class_values, right_class_values) \n",
    "                    \n",
    "        if current_info_gain > best_split.information_gain:\n",
    "            best_split.feature_name = feature_name\n",
    "            best_split.threshold = threshold\n",
    "            best_split.left_dataset = left_dataset.copy()\n",
    "            best_split.right_dataset = right_dataset.copy()\n",
    "            best_split.information_gain = current_info_gain\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DecisionTreePredictor class\n",
    "This class takes the generated tree as input and predict the output class based on the tree.\n",
    "It also calculates the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreePredictor:\n",
    "    def __init__(self, tree):\n",
    "        self.tree = tree\n",
    "\n",
    "    def predict_single(self, features, tree):\n",
    "        if tree.leaf_value is not None:\n",
    "            return tree.leaf_value\n",
    "        else:\n",
    "            if features[tree.feature_name] < tree.threshold:\n",
    "                return self.predict_single(features, tree.left)\n",
    "            else:\n",
    "                return self.predict_single(features, tree.right)\n",
    "\n",
    "    def predict(self, data):\n",
    "        predictions = []\n",
    "\n",
    "        for _, row in data.iterrows():\n",
    "            prediction = self.predict_single(row, self.tree)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        result_data_frame = data.copy()\n",
    "        result_data_frame['predicted_value'] = predictions\n",
    "        return result_data_frame\n",
    "    \n",
    "    def calculate_accuracy(self,predictions):\n",
    "        predicted_values = predictions.iloc[:, -2]  # Assuming predicted value is the second to last column\n",
    "        actual_values = predictions.iloc[:, -1]     # Assuming original label is the last column\n",
    "        \n",
    "        correct_predictions = sum(predicted_values == actual_values)\n",
    "        total_instances = len(actual_values)\n",
    "        accuracy = correct_predictions / total_instances\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SkLearnClassifier Class\n",
    "Scikit Learn Classifier Implementation.\n",
    "This class handles all the changes need to implement the scikit learn classifier and it takes input as DecisionTreeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier as SklearnDecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class SkLearnClassifier:\n",
    "    def execute(self, data:DecisionTreeData,max_depth):\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        combined_data = pd.concat([data.training_data, data.test_data], axis=0)\n",
    "\n",
    "        combined_data[data.class_column_name] = label_encoder.fit_transform(combined_data[data.class_column_name])\n",
    "\n",
    "        # Encode nominal columns\n",
    "        for column_name in data.nominal_column_names:\n",
    "            combined_data[column_name] = label_encoder.fit_transform(combined_data[column_name])\n",
    "\n",
    "        # Split combined data back into training and test sets\n",
    "        training_data = combined_data[:len(data.training_data)]\n",
    "        test_data = combined_data[len(data.training_data):]\n",
    "\n",
    "        training_data_features = training_data.drop(columns=[data.class_column_name])\n",
    "        training_data_class = training_data[data.class_column_name]\n",
    "\n",
    "        test_data_features = test_data.drop(columns=[data.class_column_name])\n",
    "        test_data_class = test_data[data.class_column_name]\n",
    "\n",
    "        classifier = SklearnDecisionTreeClassifier(criterion = data.criterion.value,max_depth=max_depth)\n",
    "        classifier.fit(training_data_features, training_data_class)\n",
    "\n",
    "        sklearn_predictions = classifier.predict(test_data_features)\n",
    "\n",
    "        return accuracy_score(test_data_class, sklearn_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Common function to train, predict based on data and perform cross validation for both classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_predict_accuracy(max_depth, min_samples, data:DecisionTreeData):\n",
    "    classifier = DecisionTreeClassifier(data, min_samples, max_depth)\n",
    "    classifier.execute()\n",
    "\n",
    "    predictor = DecisionTreePredictor(data.tree)\n",
    "    predictions =  predictor.predict(data.test_data)\n",
    "    accuracy = predictor.calculate_accuracy(predictions)\n",
    "\n",
    "    #Scikit Learn Classifier\n",
    "    sklearn_accuracy = SkLearnClassifier().execute(data,max_depth)\n",
    "    return accuracy,sklearn_accuracy\n",
    "\n",
    "def calculate_data_set(data:DecisionTreeData, index,fold_count):\n",
    "    test_data = data.folds[index]\n",
    "    other_keys = [key for key in range(fold_count) if key != index]\n",
    "    training_data = pd.concat([data.folds[key] for key in other_keys], ignore_index=True)\n",
    "    return test_data,training_data\n",
    "\n",
    "def perform_cross_validation(max_depth, min_samples, data:DecisionTreeData,fold_count):\n",
    "    data.generate_folds(fold_count)\n",
    "\n",
    "    accuracy_array = []\n",
    "    sklearn_accuracy_array = []\n",
    "    for index in range(fold_count):\n",
    "        test_data, training_data = calculate_data_set(data, index,fold_count)\n",
    "        data.reset_training_test_data(training_data,test_data)\n",
    "        accuracy, sklearn_accuracy = decision_tree_predict_accuracy(max_depth,min_samples, data)\n",
    "        accuracy_array.append(accuracy)\n",
    "        sklearn_accuracy_array.append(sklearn_accuracy)\n",
    "        print(f\"Accuracy: {accuracy * 100:.4f}%, Scikit Learn's Accuracy: {sklearn_accuracy * 100:.4f}%\")\n",
    "\n",
    "    print(f\" \\nAverage Decision Tree Accuracy: {np.average(accuracy_array) * 100:.4f}%\")\n",
    "    print(f\"Average Scikit Learn's Decision Tree Accuracy: {np.average(sklearn_accuracy_array) * 100:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classification Predictor\n",
    "`Configure the column names based on the data type into two arrays`\n",
    "1. real_valued_columns\n",
    "2. nominal_valued_columns\n",
    "\n",
    "Configure the max_depth and min_samples for the tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 90.0000%\n",
      "Scikit Learn's Decision Tree accuracy: 93.3333% \n",
      "\n",
      "Accuracy: 90.0000%, Scikit Learn's Accuracy: 96.6667%\n",
      "Accuracy: 93.3333%, Scikit Learn's Accuracy: 93.3333%\n",
      "Accuracy: 93.3333%, Scikit Learn's Accuracy: 93.3333%\n",
      "Accuracy: 93.3333%, Scikit Learn's Accuracy: 100.0000%\n",
      "Accuracy: 96.6667%, Scikit Learn's Accuracy: 93.3333%\n",
      " \n",
      "Average Decision Tree Accuracy: 93.3333%\n",
      "Average Scikit Learn's Decision Tree Accuracy: 95.3333%\n"
     ]
    }
   ],
   "source": [
    "real_valued_columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "\n",
    "source_data_frame = pd.read_csv(url, names=column_names)\n",
    "\n",
    "nominal_valued_columns = []\n",
    "max_depth = 5\n",
    "min_samples = 3\n",
    "\n",
    "# Config the data based on need\n",
    "data = DecisionTreeData(source_data_frame,SplitCriterion.ENTROPY,is_auto_column_type=False)\n",
    "data.set_column_type(real_valued_columns,nominal_valued_columns)\n",
    "data.process()\n",
    "data.train_test_split()\n",
    "\n",
    "accuracy, sklearn_accuracy = decision_tree_predict_accuracy(max_depth,min_samples, data)\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {accuracy * 100:.4f}%\")\n",
    "print(f\"Scikit Learn's Decision Tree accuracy: {sklearn_accuracy * 100:.4f}% \\n\")\n",
    "\n",
    "perform_cross_validation(max_depth,min_samples, data,fold_count=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
